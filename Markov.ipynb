{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81feb9a-a9ad-4324-80b1-e00fba9f5026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40741c28-c4dc-4246-a7f6-08fb60123ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov():\n",
    "    init_array = np.array([1,0,0])\n",
    "    E=np.array([13.5, 19.5, 25.5])\n",
    "    transfer_mat = np.array([[0.625, 0.375, 0], \n",
    "                             [0.25, 0.58, 0.17], \n",
    "                             [0, 0.67, 0.33]])\n",
    "    restmp = init_array\n",
    "    for i in range(25): \n",
    "        res = np.dot(restmp, transfer_mat) \n",
    "        Ex= np.dot(res,E.T)\n",
    "        print(f'N{i+1}\\t{res} \\n Ex \\t {Ex}') \n",
    "        restmp = res\n",
    "    # return restmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f63683c6-78e1-47b1-a3a7-94e89dabe378",
   "metadata": {},
   "outputs": [],
   "source": [
    "E=np.array([13.5, 19.5, 25.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "76ac00b8-caba-4ca4-897b-7eac528f0c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N1\t[0.625 0.375 0.   ] \n",
      " Ex \t 15.75\n",
      "N2\t[0.484375 0.451875 0.06375 ] \n",
      " Ex \t 16.97625\n",
      "N3\t[0.41570313 0.48644062 0.09785625] \n",
      " Ex \t 17.59291875\n",
      "N4\t[0.38142461 0.50358792 0.11498747] \n",
      " Ex \t 17.90137715625\n",
      "N5\t[0.36428736 0.51215683 0.12355581] \n",
      " Ex \t 18.055610700468748\n",
      "N6\t[0.35571881 0.51644111 0.12784008] \n",
      " Ex \t 18.132727624516406\n",
      "N7\t[0.35143453 0.51858325 0.12998222] \n",
      " Ex \t 18.17128609185807\n",
      "N8\t[0.3492924  0.51965432 0.13105328] \n",
      " Ex \t 18.190565325715028\n",
      "N9\t[0.34822133 0.52018985 0.13158882] \n",
      " Ex \t 18.20020494265002\n",
      "N10\t[0.34768579 0.52045762 0.13185659] \n",
      " Ex \t 18.205024751117747\n",
      "N11\t[0.34741803 0.52059151 0.13199047] \n",
      " Ex \t 18.207434655351616\n",
      "N12\t[0.34728414 0.52065845 0.13205741] \n",
      " Ex \t 18.20863960746855\n",
      "N13\t[0.3472172  0.52069192 0.13209088] \n",
      " Ex \t 18.20924208352702\n",
      "N14\t[0.34718373 0.52070865 0.13210762] \n",
      " Ex \t 18.209543321556254\n",
      "N15\t[0.34716699 0.52071702 0.13211598] \n",
      " Ex \t 18.209693940570872\n",
      "N16\t[0.34715863 0.5207212  0.13212017] \n",
      " Ex \t 18.20976925007818\n",
      "N17\t[0.34715444 0.5207233  0.13212226] \n",
      " Ex \t 18.209806904831833\n",
      "N18\t[0.34715235 0.52072434 0.13212331] \n",
      " Ex \t 18.20982573220866\n",
      "N19\t[0.34715131 0.52072487 0.13212383] \n",
      " Ex \t 18.209835145897074\n",
      "N20\t[0.34715078 0.52072513 0.13212409] \n",
      " Ex \t 18.209839852741283\n",
      "N21\t[0.34715052 0.52072526 0.13212422] \n",
      " Ex \t 18.209842206163383\n",
      "N22\t[0.34715039 0.52072532 0.13212429] \n",
      " Ex \t 18.209843382874435\n",
      "N23\t[0.34715032 0.52072536 0.13212432] \n",
      " Ex \t 18.20984397122996\n",
      "N24\t[0.34715029 0.52072537 0.13212434] \n",
      " Ex \t 18.209844265407725\n",
      "N25\t[0.34715028 0.52072538 0.13212434] \n",
      " Ex \t 18.209844412496604\n"
     ]
    }
   ],
   "source": [
    "markov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34f5394c-5fba-47b1-8ae7-da8faa801957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.209844412496604"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(restmp,E.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3be4eb0e-66e7-4814-9d33-1023061bedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "9d2d1208-e5be-48a9-b40b-2aa41c1652fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义状态转移概率矩阵P\n",
    "P = np.array([\n",
    "    [0.9, 0.1, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.5, 0.0, 0.5, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.6, 0.0, 0.4],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.3, 0.7],\n",
    "    [0.0, 0.2, 0.3, 0.5, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89ea1b11-4a97-42e8-b4cb-e5f8765cfc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_return(chain, gamma):\n",
    "    k = len(chain)\n",
    "    G = 0 \n",
    "    for i in range(k):\n",
    "        G += math.pow(gamma,i)*r_s[chain[i]-1]\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "7dd6551b-5cdc-4e5f-bb00-284d230fd481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据本序列计算得到回报为：-2.5。\n"
     ]
    }
   ],
   "source": [
    "r = np.array([-1,-2,-2,10,1,0]) #奖励函数\n",
    "# 一个状态序列,s1-s2-s3-s6\n",
    "chain = np.array([1,2,3,6])\n",
    "# 一个状态序列,s1-s2-s3-s4-s6\n",
    "# chain = np.array([1,2,3,4,6])\n",
    "## 一个状态序列,s1-s2-s3-s4-s5-s3-s6\n",
    "# chain = np.array([1,2,3,4,5,3,6])\n",
    "gamma = 0.5 #折扣因子\n",
    "G = compute_return(chain, gamma)\n",
    "print(\"根据本序列计算得到回报为：%s。\" % G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "4219b584-dba8-4532-b7cc-3c07e548253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 利用贝尔曼方程的矩阵形式计算解析解'''\n",
    "def compute_V(P,r,gamma):\n",
    "    states_num = P.shape[0] # states_num是MRP的状态数\n",
    "    rewards = r.reshape(-1,1) #奖励函数转换成列向量\n",
    "    # V = r + gamma*P*V\n",
    "    # V = inv(I-gamma*P) * r\n",
    "    value = np.dot(np.linalg.inv(np.eye(states_num,states_num) - gamma*P),\n",
    "                   rewards)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "00aeac1d-17d1-4dad-b63c-f22f1fd8c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRP中每个状态价值分别为\n",
      " [[-2.01950168]\n",
      " [-2.21451846]\n",
      " [ 1.16142785]\n",
      " [10.53809283]\n",
      " [ 3.58728554]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "V = compute_V(P,r,gamma)\n",
    "print(\"MRP中每个状态价值分别为\\n\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "605c3525-bc5c-46ad-a4d6-be4330d8a2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -2, -2, 10,  1,  0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#利用贝尔曼方程进行验证，对状态s4,gamma = 0.5，有以下：\n",
    "#V(s4) = r(s4) +gamma* sum(P(s'|s4)*V(s'))\n",
    "# r(s4) = r_s[3] = 10\n",
    "##sum(P(s'|s4)*V(s')) = P(s5|s4)*V(s5)+P(s6|s4)*V(s6) = 0.3*3.58728554+0.7*0 等价于 np.dot(P[3,:],V)\n",
    "#V(s4) = 10+0.5*0.3*3.59=10.54 = V(s4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "d34c3f19-805f-4735-9a0e-0edac4a47d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = ['s1','s2','s3','s4','s5'] #状态集合\n",
    "A = ['保持s1','前往s2','前往s1','前往s3','前往s4','前往s5','概率前往']#动作集合\n",
    "#状态转移函数\n",
    "P0 ={\n",
    "    's1-保持s1-s1':1,\n",
    "    's1-前往s2-s2':1,\n",
    "    's2-前往s1-s1':1,\n",
    "    's2-前往s3-s3':1,\n",
    "    's3-前往s4-s4': 1.0,\n",
    "    's3-前往s5-s5': 1.0,\n",
    "    's4-前往s5-s5': 1.0,\n",
    "    's4-概率前往-s2':0.2,\n",
    "    's4-概率前往-s3':0.4,\n",
    "    's4-概率前往-s4':0.4\n",
    "}\n",
    "P_mat = np.array([\n",
    "       [1, 1, 0., 0., 0.],\n",
    "       [1, 0., 1, 0., 0.],\n",
    "       [0., 0., 0., 1, 1],\n",
    "       [0., 0.2, 0.4, 0.4, 1],\n",
    "       [0., 0., 0., 0., 1]]) # s5终止状态（terminal state）,P(s5|s5) = 1 ，因为它不会再转移到其他状态，它永远以概率 1 转移到自己\n",
    "\n",
    "#奖励函数\n",
    "R0= {\n",
    "    's1-保持s1':-1,\n",
    "    's1-前往s2':0,\n",
    "    's2-前往s1':-1,\n",
    "    's2-前往s3':-2,\n",
    "    's3-前往s4':-2,\n",
    "    's3-前往s5':0,\n",
    "    's4-前往s5':10,\n",
    "    's4-概率前往':1\n",
    "}\n",
    "#R(s,a)= （5*7矩阵）\n",
    "R_mat = np.array([[-1,0, 0, 0,  0, 0,0],\n",
    "              [0 ,0,-1,-2,  0, 0,0],\n",
    "              [0 ,0, 0, 0, -2, 0,0],\n",
    "              [0 ,0, 0, 0,  0,10,1],\n",
    "              [0 ,0, 0, 0,  0, 0,0]])\n",
    "# R  = R_mat.sum(axis=1)\n",
    "# #array([-1, -3, -2, 11,  0])\n",
    "#折扣因子\n",
    "gamma = 0.5\n",
    "MDP = (S,A,P0,R0,gamma)\n",
    "#策略1\n",
    "Pi_1= {\n",
    "    's1-保持s1':0.5,\n",
    "    's1-前往s2':0.5,\n",
    "    's2-前往s1':0.5,\n",
    "    's2-前往s3':0.5,\n",
    "    's3-前往s4':0.5,\n",
    "    's3-前往s5':0.5,\n",
    "    's4-前往s5':0.5,\n",
    "    's4-概率前往':0.5 \n",
    "}\n",
    "π_mat_1 =  np.array([[0.5,0, 0, 0,  0, 0,0],\n",
    "              [0 ,0,0.5,0.5,  0, 0,0],\n",
    "              [0 ,0, 0, 0, 0.5, 0,0],\n",
    "              [0 ,0, 0, 0,  0,0.5,0.5],\n",
    "              [0 ,0, 0, 0,  0, 0,0]])\n",
    "\n",
    "π_1 = np.array([\n",
    "       [0.5, 0.5, 0., 0., 0.],\n",
    "       [0.5, 0., 0.5, 0., 0.],\n",
    "       [0., 0., 0., 0.5, 0.5],\n",
    "       [0., 0.5, 0.5, 0.5, 0.5], \n",
    "       [0., 0., 0., 0., 1]])\n",
    "#策略2\n",
    "Pi_2= {\n",
    "    's1-保持s1':0.6,\n",
    "    's1-前往s2':0.4,\n",
    "    's2-前往s1':0.3,\n",
    "    's2-前往s3':0.7,\n",
    "    's3-前往s4':0.5,\n",
    "    's3-前往s5':0.5,\n",
    "    's4-前往s5':0.1,\n",
    "    's4-概率前往':0.9\n",
    "}\n",
    "π_mat_2 =  np.array([[0.6,0.4, 0, 0,  0, 0,0],\n",
    "              [0 ,0,0.3,0.7,  0, 0,0],\n",
    "              [0 ,0, 0, 0, 0.5, 0,0],\n",
    "              [0 ,0, 0, 0,  0,0.1,0.9],\n",
    "              [0 ,0, 0, 0,  0, 0,0]])\n",
    "π_2 = np.array([\n",
    "       [0.6, 0.4, 0., 0., 0.],\n",
    "       [0.3, 0., 0.7, 0., 0.],\n",
    "       [0., 0., 0., 0.5, 0.5],\n",
    "       [0., 0.9, 0.9, 0.9, 0.1],\n",
    "       [0., 0., 0., 0., 1]])\n",
    "def join(str1,str2):\n",
    "    return str1 + '-' + str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "6d6a2d65-6ea5-4f47-a562-d74bfcf54c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(π,π_mat,P,R,MDP,Pi):\n",
    "    # 转化后的MRP的状态转移矩阵\n",
    "    S,A,P0,R0,gamma =MDP\n",
    "    P_prime = π*P\n",
    "# array([[0.5, 0.5, 0. , 0. , 0. ],\n",
    "#        [0.5, 0. , 0.5, 0. , 0. ],\n",
    "#        [0. , 0. , 0. , 0.5, 0.5],\n",
    "#        [0. , 0.1, 0.2, 0.2, 0.5],\n",
    "#        [0. , 0. , 0. , 0. , 1. ]])\n",
    "# 转化后的MRP的奖励函数\n",
    "    R_prime = (π_mat*R_mat).sum(axis=1) \n",
    "# array([-0.5, -1.5, -1. ,  5.5,  0. ])\n",
    "    V_π = compute_V(P_prime,R_prime,gamma)\n",
    "    \n",
    "    # print(\"MDP中每个状态价值分别为\\n\", V_π )\n",
    "    V_π_dict = {}\n",
    "    for i in range(len(S)):\n",
    "        V_π_dict[S[i]] = float(V_π[i])\n",
    "    print(\"MDP状态价值字典\\n\", V_π_dict )\n",
    "    Q_π_dict = compute_Q(MDP,Pi,V_π_dict)\n",
    "    print(\"MDP动作价值字典\\n\", Q_π_dict )\n",
    "    # return V_π_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "40b4570f-e901-497b-a295-eeafd8bf420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用策略一:\n",
      "MDP状态价值字典\n",
      " {'s1': -1.2255541069100393, 's2': -1.6766623207301177, 's3': 0.5189048239895697, 's4': 6.075619295958279, 's5': 0.0}\n",
      "MDP动作价值字典\n",
      " {('s1', '保持s1'): -1.6127770534550196, ('s1', '前往s2'): -0.8383311603650588, ('s2', '前往s1'): -1.6127770534550196, ('s2', '前往s3'): -1.740547588005215, ('s3', '前往s4'): 1.0378096479791394, ('s3', '前往s5'): 0.0, ('s4', '前往s5'): 10.0, ('s4', '概率前往'): 2.1512385919165578}\n",
      "使用策略二:\n",
      "MDP状态价值字典\n",
      " {'s1': -1.4558505073116133, 's2': -2.0954767755906465, 's3': -0.5059977128397284, 's4': 1.976009148641086, 's5': 0.0}\n",
      "MDP动作价值字典\n",
      " {('s1', '保持s1'): -1.7279252536558065, ('s1', '前往s2'): -1.0477383877953232, ('s2', '前往s1'): -1.7279252536558065, ('s2', '前往s3'): -2.252998856419864, ('s3', '前往s4'): -1.011995425679457, ('s3', '前往s5'): 0.0, ('s4', '前往s5'): 10.0, ('s4', '概率前往'): 1.0844546096012069}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6r/z2lzrvf17j52yzjsk2swb45w0000gn/T/ipykernel_41731/3202457662.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  V_π_dict[S[i]] = float(V_π[i])\n"
     ]
    }
   ],
   "source": [
    "##使用策略1 Pi_1\n",
    "print('使用策略一:')\n",
    "fit(π_1,π_mat_1,P_mat,R_mat,MDP,Pi_1)\n",
    "##使用策略1 Pi_2\n",
    "print('使用策略二:')\n",
    "fit(π_2,π_mat_2,P_mat,R_mat,MDP,Pi_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "6a40ef6e-75f2-4859-a3ee-9acacd4a33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Q(MDP,Pi_1,V_π_dict):\n",
    "    S,A,P0,R0,gamma = MDP\n",
    "    Q_π_dict ={}\n",
    "    for key in Pi_1.keys():\n",
    "        s,a=key.split('-')\n",
    "        r = R0[key]\n",
    "        temp,c = 0 ,0# rand是随机数，大于0 \n",
    "        for s_opt in S:\n",
    "            temp += P0.get(join(key,s_opt),0)#遍历查找，如果（s,a_opt,s_opt）在状态转移概率中找不到，返回0\n",
    "            if temp > 0:# 筛选非None的（s,a_opt，s_opt）对，取值\n",
    "                s_next = s_opt\n",
    "                c += P0.get(join(key,s_opt),0)*V_π_dict[s_next]\n",
    "        Q_π_dict[(s,a)] = r + gamma*c\n",
    "    # print(\"计算MDP的动作价值为\\n\", Q_π_dict)\n",
    "    return Q_π_dict\n",
    "Q_π_dict = compute_Q(MDP,Pi_1,V_π_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "203bc4ad-7a0d-4d3d-83a1-d1e74de299b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(MDP,π,timestep_max,number):\n",
    "    S,A,P,R,gamma = MDP\n",
    "    episodes = []\n",
    "    for num in range(number):\n",
    "        episode= []\n",
    "        timestep = 0\n",
    "        s = S[np.random.randint(4)] # 随机选择一个除s5以外的状态s作为起点\n",
    "        # np.random.shuffle(A)\n",
    "        # 当前状态为终止状态或者时间步太长时,一次采样结束\n",
    "        while s != 's5' and timestep <= timestep_max:\n",
    "            timestep += 1\n",
    "            rand, temp = np.random.rand(), 0 #rand是随机数，大于0 \n",
    "             # 在状态s下根据策略选择动作\n",
    "            for a_opt in A:\n",
    "                temp += π.get(join(s,a_opt),0) #遍历查找，如果（s,a_opt）在动作策略中找不到，返回0\n",
    "                if temp > rand: # 筛选非None的（s,a_opt）对，取值\n",
    "                    a = a_opt\n",
    "                    r = R.get(join(s,a))\n",
    "                    break\n",
    "            rand, temp = np.random.rand(), 0 #rand是随机数，大于0 \n",
    "            # 根据状态转移概率得到下一个状态s_next\n",
    "            for s_opt in S:\n",
    "                temp += P.get(join(join(s,a_opt),s_opt),0)#遍历查找，如果（s,a_opt,s_opt）在状态转移概率中找不到，返回0\n",
    "                if temp > rand:# 筛选非None的（s,a_opt，s_opt）对，取值\n",
    "                    s_next = s_opt \n",
    "                    break\n",
    "            episode.append((s,a,r,s_next))\n",
    "            s = s_next\n",
    "        # print(f'第{num+1}条序列\\n', episode)\n",
    "        episodes.append(episode)\n",
    "        num += 1\n",
    "    return episodes\n",
    "# 采样5次,每个序列最长不超过20步\n",
    "episodes = sample(MDP,Pi_1,20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "693c55d5-382e-41a4-a7b5-8b44953f7e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用蒙特卡洛方法计算MDP的状态价值为\n",
      " {'s1': -1.2139343182008653, 's2': -1.6651032093089706, 's3': 0.5146363402066164, 's4': 6.246285732778469, 's5': 0}\n"
     ]
    }
   ],
   "source": [
    "def MC(episodes,V,N,gamma):\n",
    "    for episode in episodes:\n",
    "        G = 0\n",
    "        for i in range(len(episode)-1,-1,-1):#一个序列从后往前计算\n",
    "            (s,a,r,s_next) = episode[i]\n",
    "            G = r + gamma*G\n",
    "            N[s] =  N[s] + 1\n",
    "            V[s] =  V[s] + (G - V[s]) / N[s]\n",
    "    print(\"使用蒙特卡洛方法计算MDP的状态价值为\\n\", V)\n",
    "    return V\n",
    "# 采样1000次,可以自行修改\n",
    "episodes = sample(MDP, Pi_1, 20, 1000)\n",
    "V,N = {'s1': 0, 's2': 0, 's3': 0, 's4': 0, 's5': 0},{'s1': 0, 's2': 0, 's3': 0, 's4': 0, 's5': 0}\n",
    "V = MC(episodes,V,N,gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "72c2808e-d380-493a-9702-e164b3d2e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = compute_Q(MDP,Pi_1,V)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
